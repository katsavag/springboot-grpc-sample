# ArrayList

An ArrayList is a resizable array-based data structure that internally maintains a contiguous block of memory to store elements, much like a standard array, but with the ability to grow dynamically when more capacity is needed. When the current capacity is exceeded, the ArrayList automatically creates a new, larger array (often by increasing its size by about 50% or doubling it, depending on the implementation) and copies the existing elements into it, which is why adding elements is usually fast but can occasionally be costly during a resize. Accessing an element by index is an O(1) operation since it directly maps to the underlying array, while adding or removing elements at the end is on average O(1) amortized, though removals require shifting references if not at the last position. Inserting or deleting elements at arbitrary positions has a worst-case cost of O(n) because all subsequent elements must be shifted to preserve order. ArrayLists are best used when you need fast random access and frequent additions at the end, but they are less efficient for scenarios requiring many insertions or deletions in the middle of the collection.

# LinkedList

A LinkedList is a node-based data structure where each element is stored in a separate object called a node, which holds both the value and a reference (or pointer) to the next node, and in a doubly linked list, also to the previous node. Unlike an array-based structure, a LinkedList does not require a contiguous block of memory, and elements can be easily inserted or removed by adjusting node references without shifting other elements, which makes insertion and deletion operations O(1) if the position is already known. However, accessing an element by index requires sequential traversal from the head (or tail, in a doubly linked list), leading to a time complexity of O(n). Adding elements at the beginning or end is efficient, usually O(1), while random access is slow compared to an ArrayList. LinkedLists are particularly useful when the application involves frequent insertions and deletions in the middle of the collection or when memory reallocation costs of arrays are undesirable, but they are less suitable when fast random access or cache-friendly performance is required.

# Vector 

A Vector is a dynamic array-based data structure in Java, very similar to an ArrayList, but with one key difference: it is synchronized, meaning its methods are thread-safe for concurrent access by multiple threads. Internally, a Vector maintains a contiguous array to store elements, and when the array becomes full, it resizes itself by allocating a larger array (often doubling its size) and copying existing elements over. Element access by index is an O(1) operation because it directly maps to the underlying array, while adding elements at the end is typically O(1) amortized, except when resizing occurs. Inserting or removing elements at arbitrary positions costs O(n) because subsequent elements must be shifted, just like in an ArrayList. Due to its synchronization overhead, a Vector is generally slower in single-threaded applications, making it preferable only when thread safety is required without external synchronization. Otherwise, an ArrayList is usually the better choice for performance and simplicity.

# HashSet

A HashSet is a collection class in Java that implements the Set interface and stores unique elements using a hash table as its underlying data structure. Internally, it is backed by a HashMap, where each element of the set is stored as a key in the map with a dummy constant value. When an element is added, its hashCode() is computed to determine the appropriate bucket, and within that bucket, the element is compared using equals() to ensure uniqueness, which means duplicates are automatically ignored. The runtime complexity of the basic operations—add, remove, and contains—is O(1) average case, since hashing distributes elements efficiently across buckets, but can degrade to O(n) in the worst case if many elements collide into the same bucket (though this is rare with a good hash function). Iteration over a HashSet is O(n), but with no guaranteed order of elements, since they are arranged based on hash codes. A HashSet is best used when fast membership testing, insertion, and deletion of unique elements are required without caring about order, such as eliminating duplicates from a collection or implementing lookups.

# LinkedHashSet

A LinkedHashSet is a hash table and linked list implementation of the Set interface that combines the constant-time performance of a HashSet with a predictable iteration order. Internally, it is backed by a LinkedHashMap, which uses hashing to store unique elements in buckets while also maintaining a doubly linked list that preserves the order in which elements were inserted. Like a HashSet, the fundamental operations—add, remove, and contains—run in O(1) average time, with a possible worst case of O(n) if many elements hash to the same bucket. Unlike HashSet, iteration over a LinkedHashSet is O(n) but guarantees traversal in insertion order (or access order if configured via the map constructor). This makes LinkedHashSet especially useful when you need the uniqueness and quick lookups of a hash-based set but also want to preserve element order, such as for building caches, implementing ordered sets, or processing items in the order they were originally added.

# TreeSet

A TreeSet is a collection in Java that implements the NavigableSet interface and stores unique elements in a balanced binary search tree, specifically a Red-Black Tree. Unlike hash-based sets, a TreeSet keeps its elements in sorted order, either according to their natural ordering (via the Comparable interface) or a custom order provided by a Comparator. Internally, each insertion locates the correct position in the tree, and rebalancing ensures that the height of the tree remains logarithmic relative to the number of elements. Because of this structure, the core operations—add, remove, and contains—all run in O(log n) time. Iteration is O(n) but guarantees traversal in sorted order, which makes TreeSet particularly useful when you need fast access to ordered data or need to perform range queries, such as retrieving elements greater than or less than a given value. However, it has higher overhead than a HashSet or LinkedHashSet, so it is best used when ordering and sorted access are important, not just uniqueness.

# PriorityQueue

A PriorityQueue in Java is a queue-based collection that orders its elements according to their natural ordering or a custom Comparator, but unlike a normal queue, it retrieves elements based on priority rather than insertion order. Internally, it is implemented as a binary heap, typically a min-heap, stored in a resizable array where the smallest element is always at the root. This structure allows the insertion (offer) operation to run in O(log n) because the element must “bubble up” to maintain heap order, while removal of the head (poll) also runs in O(log n) due to reheapification. Accessing the head element without removal (peek) is O(1) since it is always at the root, but searching for arbitrary elements or removing non-head elements costs O(n) because the heap does not support efficient random access. Iteration over the PriorityQueue is O(n) but does not guarantee sorted order, only heap order. A PriorityQueue is best used when tasks require efficient retrieval of the smallest (or largest, with a max-heap comparator) element, such as in scheduling systems, graph algorithms like Dijkstra’s, or any situation where processing order is determined by priority rather than insertion sequence.

# ArrayDequeue

An ArrayDeque in Java is a resizable, array-backed implementation of the Deque interface that supports insertion and removal of elements from both ends in constant time. Internally, it maintains a circular buffer in which the head and tail pointers wrap around the underlying array, avoiding the need to shift elements as in an ArrayList. When the buffer becomes full, the ArrayDeque doubles its capacity and copies elements into a new array, which makes growth amortized efficient. The basic operations—addFirst, addLast, removeFirst, and removeLast—all run in O(1) amortized, and access to the front or back elements (peekFirst, peekLast) is also O(1). Unlike a LinkedList, it provides better cache locality and avoids the overhead of node allocations, making it faster in most scenarios. However, random access by index is not supported, as the structure is optimized only for double-ended queue behavior. ArrayDeque is best used when you need a general-purpose queue or stack replacement that requires fast insertions and deletions at both ends, such as in breadth-first search, sliding window algorithms, or implementing stacks more efficiently than Stack.

# WeakHashMap

A WeakHashMap in Java is a hash table–based implementation of the Map interface where the keys are stored as weak references, meaning they do not prevent their referents from being garbage-collected. Internally, it works like a normal HashMap with buckets for hashing, but each key is wrapped in a WeakReference object. When the garbage collector determines that a key is no longer in ordinary use (no strong references exist), the entry is automatically removed from the map during the next cleanup process. The basic operations—get, put, and remove—have O(1) average time complexity, though, like any hash-based collection, performance may degrade to O(n) in cases of poor hashing or excessive collisions. Iteration is O(n) over the current entries, but the order is not guaranteed. A WeakHashMap is most useful in scenarios where you need to associate metadata with objects without preventing their collection, such as caching, object pooling, or storing listeners, making it a memory-sensitive alternative to regular hash-based maps.

# IdentityHashMap

An IdentityHashMap in Java is a hash table–based implementation of the Map interface that uses reference equality (==) instead of the equals() method to compare keys, and relies on the system’s identity hash code (System.identityHashCode) instead of the object’s hashCode() method. Internally, it maintains an array where keys and values are stored in adjacent slots, providing compact storage but no ordering guarantees. The basic operations—put, get, and remove—run in O(1) average time, though performance may degrade to O(n) if many hash collisions occur. Since keys are compared by reference, two different objects that are logically equal (according to equals) are treated as distinct keys, which makes this map fundamentally different from a HashMap. Iteration is O(n) and order is undefined, as with most hash-based structures. An IdentityHashMap is best used in niche cases such as implementing object graph traversals, maintaining object-to-metadata associations without risk of key confusion, or performance-sensitive frameworks where identity comparison is both sufficient and faster than logical equality checks.





